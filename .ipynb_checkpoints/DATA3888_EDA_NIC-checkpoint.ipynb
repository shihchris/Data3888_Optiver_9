{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "072bfeed",
   "metadata": {},
   "source": [
    "## EDA: Clustering based on ARMA-Garch model features + Model Comparison on each cluster\n",
    "- ### Models tested were ARMA - Garch and AR - EWMA\n",
    "- ### Both AREWMA (Autoregressive Exponentially Weighted Moving Average) and ARMA-GARCH are traditional statistical models used for time series analysis   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5740bd66",
   "metadata": {},
   "source": [
    "#### The code below is to understand what columns are in the parquet files prints out first few lines of a random parquet file, imports are done seperately because each code block was done at seperate times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724d12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "File 1: stock_94.parquet\n",
      "==================================================\n",
      "Shape: (1191489, 16)\n",
      "Columns: ['time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_price2', 'ask_price2', 'bid_size1', 'ask_size1', 'bid_size2', 'ask_size2', 'stock_id', 'WAP', 'BidAskSpread', 'log_return', 'time_bucket', 'volatility']\n",
      "\n",
      "First 5 rows:\n",
      "   time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  ask_price2  \\\n",
      "0        5                  0    1.000301    1.000903    1.000129    1.000989   \n",
      "1        5                  3    1.000301    1.000903    1.000129    1.000989   \n",
      "2        5                  4    1.000301    1.000903    1.000043    1.000989   \n",
      "3        5                  5    1.000301    1.000817    1.000043    1.000903   \n",
      "4        5                  6    1.000301    1.000817    1.000043    1.000903   \n",
      "\n",
      "   bid_size1  ask_size1  bid_size2  ask_size2  stock_id       WAP  \\\n",
      "0        101         60        101         10        94  1.000679   \n",
      "1        101         60        101         10        94  1.000679   \n",
      "2        101         71          1         10        94  1.000655   \n",
      "3          1         20        301         60        94  1.000326   \n",
      "4          1         11        301         60        94  1.000344   \n",
      "\n",
      "   BidAskSpread  log_return  time_bucket  volatility  \n",
      "0      0.000602         NaN            0         NaN  \n",
      "1      0.000602    0.000000            1    0.000733  \n",
      "2      0.000602   -0.000024            1    0.000733  \n",
      "3      0.000516   -0.000329            1    0.000733  \n",
      "4      0.000516    0.000018            1    0.000733  \n",
      "\n",
      "==================================================\n",
      "File 2: stock_84.parquet\n",
      "==================================================\n",
      "Shape: (1949019, 16)\n",
      "Columns: ['time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_price2', 'ask_price2', 'bid_size1', 'ask_size1', 'bid_size2', 'ask_size2', 'stock_id', 'WAP', 'BidAskSpread', 'log_return', 'time_bucket', 'volatility']\n",
      "\n",
      "First 5 rows:\n",
      "   time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  ask_price2  \\\n",
      "0        5                  0    1.001911    1.002451    1.001872    1.002490   \n",
      "1        5                  1    1.002027    1.002490    1.001988    1.002567   \n",
      "2        5                  2    1.001911    1.002258    1.001795    1.002374   \n",
      "3        5                  3    1.002027    1.002490    1.001988    1.002529   \n",
      "4        5                  4    1.002374    1.002606    1.002065    1.002644   \n",
      "\n",
      "   bid_size1  ask_size1  bid_size2  ask_size2  stock_id       WAP  \\\n",
      "0          1         25         25         26        84  1.001932   \n",
      "1         25          1         25         25        84  1.002472   \n",
      "2          1        100          1         25        84  1.001914   \n",
      "3         17          1         95         25        84  1.002464   \n",
      "4         17         25         25         25        84  1.002468   \n",
      "\n",
      "   BidAskSpread  log_return  time_bucket  volatility  \n",
      "0      0.000539         NaN            0         NaN  \n",
      "1      0.000462    0.000539            1     0.00156  \n",
      "2      0.000347   -0.000557            1     0.00156  \n",
      "3      0.000462    0.000549            1     0.00156  \n",
      "4      0.000231    0.000004            1     0.00156  \n",
      "\n",
      "==================================================\n",
      "File 3: stock_103.parquet\n",
      "==================================================\n",
      "Shape: (916480, 16)\n",
      "Columns: ['time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_price2', 'ask_price2', 'bid_size1', 'ask_size1', 'bid_size2', 'ask_size2', 'stock_id', 'WAP', 'BidAskSpread', 'log_return', 'time_bucket', 'volatility']\n",
      "\n",
      "First 5 rows:\n",
      "   time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  ask_price2  \\\n",
      "0        5                  0    1.001217    1.002168    1.001203    1.002254   \n",
      "1        5                  1    1.001217    1.001736    1.001203    1.002168   \n",
      "2        5                  5    1.001217    1.002168    1.001203    1.002254   \n",
      "3        5                  6    1.001217    1.001736    1.001203    1.002168   \n",
      "4        5                  7    1.001217    1.001736    1.001203    1.001995   \n",
      "\n",
      "   bid_size1  ask_size1  bid_size2  ask_size2  stock_id       WAP  \\\n",
      "0          2          1         13         12       103  1.001851   \n",
      "1          2         14         13          1       103  1.001282   \n",
      "2          2          1         13         10       103  1.001851   \n",
      "3          2         14         13        101       103  1.001282   \n",
      "4          3         14         13         10       103  1.001309   \n",
      "\n",
      "   BidAskSpread  log_return  time_bucket  volatility  \n",
      "0      0.000949         NaN            0         NaN  \n",
      "1      0.000518   -0.000568            1    0.001606  \n",
      "2      0.000949    0.000568            1    0.001606  \n",
      "3      0.000518   -0.000568            1    0.001606  \n",
      "4      0.000518    0.000027            1    0.001606  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import os\n",
    "\n",
    "# Directory containing your parquet files\n",
    "parquet_dir = \".\"  # Change this to your parquet directory path if different\n",
    "\n",
    "# Get a list of all parquet files in the directory\n",
    "parquet_files = [f for f in os.listdir(parquet_dir) if f.endswith('.parquet')]\n",
    "\n",
    "# Display the first few rows of the first three files\n",
    "for i, file in enumerate(parquet_files[:3]):\n",
    "    file_path = os.path.join(parquet_dir, file)\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"File {i+1}: {file}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Read the parquet file\n",
    "    df = pd.read_parquet(file_path)\n",
    "    \n",
    "    # Display basic info\n",
    "    print(f\"Shape: {df.shape}\")\n",
    "    print(f\"Columns: {df.columns.tolist()}\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    print(df.head())\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea3f18b",
   "metadata": {},
   "source": [
    "#### The code below is to understand the number of unique time-ids and its distribution\n",
    "#### Results:\n",
    "- #### 3830 unique time ids in stock 94"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99690c9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique time_ids: 3830\n",
      "First 20 unique time_ids: [5, 11, 16, 31, 62, 72, 97, 103, 109, 123, 128, 146, 147, 152, 157, 159, 169, 207, 211, 213]\n",
      "\n",
      "Min rows per time_id: 132\n",
      "Max rows per time_id: 599\n",
      "Average rows per time_id: 393.61\n",
      "\n",
      "Sample distribution (rows per time_id):\n",
      "time_id\n",
      "5      575\n",
      "11     370\n",
      "16     353\n",
      "31     171\n",
      "62     227\n",
      "72     514\n",
      "97     421\n",
      "103    487\n",
      "109    564\n",
      "123    516\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Path to one of your parquet files\n",
    "file_path = \"stock_1.parquet\"  # Adjust this path\n",
    "\n",
    "# Read the parquet file\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Get unique time_ids and sort them\n",
    "unique_time_ids = sorted(df['time_id'].unique())\n",
    "\n",
    "# Print the number of unique time_ids\n",
    "print(f\"Number of unique time_ids: {len(unique_time_ids)}\")\n",
    "\n",
    "# Print the first 20 unique time_ids (to avoid printing too many)\n",
    "print(f\"First 20 unique time_ids: {unique_time_ids[:20]}\")\n",
    "\n",
    "# Get the distribution/count of rows for each time_id\n",
    "time_id_counts = df['time_id'].value_counts().sort_index()\n",
    "\n",
    "# Print some statistics about the distribution\n",
    "print(f\"\\nMin rows per time_id: {time_id_counts.min()}\")\n",
    "print(f\"Max rows per time_id: {time_id_counts.max()}\")\n",
    "print(f\"Average rows per time_id: {time_id_counts.mean():.2f}\")\n",
    "\n",
    "# Print the distribution for the first few time_ids\n",
    "print(\"\\nSample distribution (rows per time_id):\")\n",
    "print(time_id_counts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b030a5d9",
   "metadata": {},
   "source": [
    "#### This code is to select 100 out of 3830 time-ids 500 time ids were not selected because other operations (see next code block) were too computationally intensive (took too long to run my laptop ran out of application memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f93266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First time_id: 5\n",
      "Middle time_id: 15853\n",
      "Last time_id: 32767\n",
      "\n",
      "Selected 100 time_ids:\n",
      "[5, 335, 697, 1107, 1326, 1640, 1938, 2178, 2479, 2833, 3113, 3469, 3877, 4138, 4460, 4743, 5101, 5407, 5729, 5978, 6325, 6643, 6930, 7245, 7629, 7921, 8441, 8718, 9091, 9367, 9819, 10100, 10491, 10781, 11070, 11431, 11764, 12030, 12348, 12661, 12965, 13318, 13579, 13868, 14176, 14452, 14795, 15038, 15418, 15728, 15989, 16404, 16704, 17029, 17305, 17606, 17914, 18184, 18502, 18836, 19157, 19488, 19747, 20135, 20460, 20827, 21145, 21507, 21891, 22249, 22622, 22922, 23220, 23531, 23863, 24224, 24707, 25059, 25347, 25636, 25924, 26307, 26603, 26944, 27240, 27595, 27964, 28379, 28801, 29171, 29590, 29941, 30313, 30624, 31047, 31322, 31609, 32083, 32463, 32767]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Path to one of your parquet files\n",
    "file_path = \"stock_1.parquet\"  # Adjust this path\n",
    "\n",
    "# Read the parquet file\n",
    "df = pd.read_parquet(file_path)\n",
    "\n",
    "# Get unique time_ids and sort them\n",
    "unique_time_ids = sorted(df['time_id'].unique())\n",
    "\n",
    "# Get first, middle, and last time_ids\n",
    "first_time_id = unique_time_ids[0]\n",
    "middle_time_id = unique_time_ids[len(unique_time_ids)//2]\n",
    "last_time_id = unique_time_ids[-1]\n",
    "\n",
    "print(f\"First time_id: {first_time_id}\")\n",
    "print(f\"Middle time_id: {middle_time_id}\")\n",
    "print(f\"Last time_id: {last_time_id}\")\n",
    "\n",
    "# Select a total of 500 time_ids spread across the dataset\n",
    "num_samples = 100\n",
    "\n",
    "# Check if we have enough unique time_ids\n",
    "if len(unique_time_ids) <= num_samples:\n",
    "    selected_time_ids = unique_time_ids\n",
    "    print(f\"\\nUsing all {len(unique_time_ids)} available time_ids:\")\n",
    "else:\n",
    "    # Use linspace to get evenly distributed indices\n",
    "    selected_indices = np.linspace(0, len(unique_time_ids)-1, num_samples, dtype=int)\n",
    "    selected_time_ids = [unique_time_ids[i] for i in selected_indices]\n",
    "    print(f\"\\nSelected {num_samples} time_ids:\")\n",
    "\n",
    "print(selected_time_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646adace",
   "metadata": {},
   "source": [
    "#### The code below filters out 100 time ids that were selected, performs feature calculation and stores them for clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b8f52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing stock 94...\n",
      "Processing stock 84...\n",
      "Processing stock 103...\n",
      "Processing stock 113...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.cluster import KMeans\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "from statsmodels.tsa.stattools import adfuller, acf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Directory containing parquet files\n",
    "parquet_dir = \".\"  # Change this to your directory\n",
    "\n",
    "# Use the time_ids we identified\n",
    "selected_time_ids = [5, 335, 697, 1107, 1326, 1640, 1938, 2178, 2479, 2833, 3113, 3469, 3877, 4138, 4460, 4743, 5101, 5407, 5729, 5978, 6325, 6643, 6930, 7245, 7629, 7921, 8441, 8718, 9091, 9367, 9819, 10100, 10491, 10781, 11070, 11431, 11764, 12030, 12348, 12661, 12965, 13318, 13579, 13868, 14176, 14452, 14795, 15038, 15418, 15728, 15989, 16404, 16704, 17029, 17305, 17606, 17914, 18184, 18502, 18836, 19157, 19488, 19747, 20135, 20460, 20827, 21145, 21507, 21891, 22249, 22622, 22922, 23220, 23531, 23863, 24224, 24707, 25059, 25347, 25636, 25924, 26307, 26603, 26944, 27240, 27595, 27964, 28379, 28801, 29171, 29590, 29941, 30313, 30624, 31047, 31322, 31609, 32083, 32463, 32767]\n",
    "# Dictionary to store ARMA-GARCH relevant features for each stock\n",
    "stock_features = {}\n",
    "\n",
    "# Find all parquet files in the directory\n",
    "parquet_files = glob.glob(os.path.join(parquet_dir, \"stock_*.parquet\"))\n",
    "\n",
    "for file_path in parquet_files:\n",
    "    # Extract stock_id from filename\n",
    "    stock_id = os.path.basename(file_path).split(\"_\")[1].split(\".\")[0]\n",
    "    print(f\"Processing stock {stock_id}...\")\n",
    "    \n",
    "    try:\n",
    "        # Read the parquet file\n",
    "        df = pd.read_parquet(file_path)\n",
    "        \n",
    "        # Filter for selected time_ids only\n",
    "        subset = df[df['time_id'].isin(selected_time_ids)]\n",
    "        \n",
    "        if subset.empty or len(subset) < 100:  # Need sufficient data\n",
    "            print(f\"  Warning: Insufficient data for stock {stock_id}\")\n",
    "            continue\n",
    "        \n",
    "        # Sort by time_id and seconds_in_bucket to ensure time order\n",
    "        subset = subset.sort_values(['time_id', 'seconds_in_bucket'])\n",
    "        \n",
    "        # Focus on log returns for ARMA-GARCH analysis\n",
    "        returns = subset['log_return'].dropna()\n",
    "        \n",
    "        if len(returns) < 100:  # Need sufficient non-NA returns\n",
    "            print(f\"  Warning: Insufficient return data for stock {stock_id}\")\n",
    "            continue\n",
    "            \n",
    "        # ARMA relevant features\n",
    "        \n",
    "        # 1. Test for serial correlation (Ljung-Box test)\n",
    "        lb_test = acorr_ljungbox(returns, lags=[10], return_df=True)\n",
    "        serial_corr_pvalue = lb_test['lb_pvalue'].values[0]\n",
    "        \n",
    "        # 2. Calculate autocorrelation at different lags\n",
    "        acf_values = acf(returns, nlags=10)\n",
    "        \n",
    "        # 3. Test for stationarity (Augmented Dickey-Fuller test)\n",
    "        adf_result = adfuller(returns)\n",
    "        adf_pvalue = adf_result[1]\n",
    "        \n",
    "        # GARCH relevant features\n",
    "        \n",
    "        # 1. Volatility clustering - autocorrelation in squared returns\n",
    "        squared_returns = returns**2\n",
    "        sq_acf_values = acf(squared_returns, nlags=10)\n",
    "        \n",
    "        # 2. Test for ARCH effects (Ljung-Box test on squared returns)\n",
    "        arch_test = acorr_ljungbox(squared_returns, lags=[10], return_df=True)\n",
    "        arch_effect_pvalue = arch_test['lb_pvalue'].values[0]\n",
    "        \n",
    "        # 3. Calculate kurtosis (excess kurtosis suggests fat tails)\n",
    "        excess_kurtosis = returns.kurtosis()\n",
    "        \n",
    "        # 4. Calculate volatility of volatility (standard deviation of rolling volatility)\n",
    "        rolling_vol = returns.rolling(window=20).std().dropna()\n",
    "        vol_of_vol = rolling_vol.std()\n",
    "        \n",
    "        # Store features\n",
    "        stock_features[stock_id] = {\n",
    "            'stock_id': int(stock_id),\n",
    "            # ARMA features\n",
    "            'serial_corr_pvalue': serial_corr_pvalue,  # Lower suggests ARMA suitability\n",
    "            'acf_lag1': acf_values[1],  # First-order autocorrelation\n",
    "            'acf_lag5': acf_values[5],  # 5th-order autocorrelation\n",
    "            'adf_pvalue': adf_pvalue,  # Lower suggests stationarity\n",
    "            # GARCH features\n",
    "            'arch_effect_pvalue': arch_effect_pvalue,  # Lower suggests GARCH suitability\n",
    "            'sq_acf_lag1': sq_acf_values[1],  # Volatility clustering\n",
    "            'sq_acf_lag5': sq_acf_values[5],  # Volatility persistence\n",
    "            'excess_kurtosis': excess_kurtosis,  # Higher suggests fat tails\n",
    "            'vol_of_vol': vol_of_vol,  # Volatility of volatility\n",
    "            # Basic statistics\n",
    "            'mean_return': returns.mean(),\n",
    "            'std_return': returns.std(),\n",
    "            'mean_spread': subset['BidAskSpread'].mean(),\n",
    "            'observations': len(returns)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  Error processing stock {stock_id}: {e}\")\n",
    "\n",
    "# Convert to DataFrame for clustering\n",
    "clustering_df = pd.DataFrame.from_dict(stock_features, orient='index')\n",
    "\n",
    "# Check if we have data\n",
    "if clustering_df.empty:\n",
    "    print(\"No data could be processed. Check your selected time_ids.\")\n",
    "else:\n",
    "    print(f\"Created clustering dataframe with shape: {clustering_df.shape}\")\n",
    "    \n",
    "    # Save this DataFrame for later use\n",
    "    clustering_df.to_csv(\"arma_garch_features.csv\")\n",
    "    \n",
    "    print(\"Completed creating features for ARMA-GARCH clustering\")\n",
    "    \n",
    "    # Display a sample of the data\n",
    "    print(\"\\nSample of the clustering dataframe:\")\n",
    "    print(clustering_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81655c9",
   "metadata": {},
   "source": [
    "#### The code below just takes the time ids that were stored and performs clustering based on arma garch features and produces visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c62b7b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- FINDING OPTIMAL NUMBER OF CLUSTERS ---\n",
      "For n_clusters = 2, the silhouette score is 0.2435379520170128\n",
      "For n_clusters = 3, the silhouette score is 0.245789617196499\n",
      "For n_clusters = 4, the silhouette score is 0.17138915106726688\n",
      "For n_clusters = 5, the silhouette score is 0.15753062714040547\n",
      "For n_clusters = 6, the silhouette score is 0.1585881966035648\n",
      "For n_clusters = 7, the silhouette score is 0.13586813429552996\n",
      "For n_clusters = 8, the silhouette score is 0.1700813591885071\n",
      "For n_clusters = 9, the silhouette score is 0.13599067710025017\n",
      "For n_clusters = 10, the silhouette score is 0.1521860875394228\n",
      "\n",
      "Best number of clusters: 3\n",
      "\n",
      "--- CLUSTER DISTRIBUTION ---\n",
      "Cluster 0: 66 stocks\n",
      "Cluster 1: 45 stocks\n",
      "Cluster 2: 1 stocks\n",
      "\n",
      "--- CREATING VISUALIZATIONS ---\n",
      "Generating silhouette score plot...\n",
      "Performing PCA and visualizing clusters...\n",
      "PCA Component 1 explains 37.13% of variance\n",
      "PCA Component 2 explains 13.21% of variance\n",
      "Total variance explained: 50.34%\n",
      "\n",
      "--- CLUSTER CENTERS ---\n",
      "           Unnamed: 0  serial_corr_pvalue  acf_lag1  acf_lag5  adf_pvalue  \\\n",
      "Cluster 0    0.061676           -0.094384  0.434470  0.125038         0.0   \n",
      "Cluster 1   -0.078824           -0.095688 -0.686211 -0.193432         0.0   \n",
      "Cluster 2   -0.523559           10.535316  2.204468  0.451920         0.0   \n",
      "\n",
      "           arch_effect_pvalue  sq_acf_lag1  sq_acf_lag5  excess_kurtosis  \\\n",
      "Cluster 0       1.019581e-232    -0.099097    -0.004337        -0.008187   \n",
      "Cluster 1      -1.462877e-232     0.104450     0.019003         0.014534   \n",
      "Cluster 2      -1.462877e-232     1.840164    -0.568881        -0.113704   \n",
      "\n",
      "           vol_of_vol  mean_return  std_return  mean_spread  observations  \n",
      "Cluster 0   -0.647746    -0.319624   -0.636820    -0.627201      0.613243  \n",
      "Cluster 1    0.983449     0.474985    0.968310     0.952896     -0.939875  \n",
      "Cluster 2   -1.503986    -0.279140   -1.543863    -1.485054      1.820327  \n",
      "\n",
      "--- KEY ARMA-GARCH FEATURES BY CLUSTER ---\n",
      "\n",
      "Feature: serial_corr_pvalue\n",
      "                  mean            std       min            max\n",
      "cluster                                                       \n",
      "0         2.541720e-06   2.043410e-05  0.000000   1.660250e-04\n",
      "1        2.025044e-123  1.358441e-122  0.000000  9.112700e-122\n",
      "2         2.072760e-02            NaN  0.020728   2.072760e-02\n",
      "\n",
      "Feature: arch_effect_pvalue\n",
      "                  mean  std  min            max\n",
      "cluster                                        \n",
      "0        2.482458e-232  0.0  0.0  1.638422e-230\n",
      "1         0.000000e+00  0.0  0.0   0.000000e+00\n",
      "2         0.000000e+00  NaN  0.0   0.000000e+00\n",
      "\n",
      "Feature: acf_lag1\n",
      "             mean       std       min       max\n",
      "cluster                                        \n",
      "0       -0.121142  0.067847 -0.247286  0.004242\n",
      "1       -0.198246  0.033259 -0.295486 -0.119629\n",
      "2        0.000635       NaN  0.000635  0.000635\n",
      "\n",
      "Feature: sq_acf_lag1\n",
      "             mean       std       min       max\n",
      "cluster                                        \n",
      "0        0.182128  0.061746  0.064675  0.352636\n",
      "1        0.195714  0.072455  0.100434  0.495239\n",
      "2        0.311566       NaN  0.311566  0.311566\n",
      "\n",
      "Feature: excess_kurtosis\n",
      "              mean        std        min         max\n",
      "cluster                                             \n",
      "0        27.407550  42.288683   6.014917  343.172832\n",
      "1        28.175342  16.250201  10.344354  108.407474\n",
      "2        23.841924        NaN  23.841924   23.841924\n",
      "\n",
      "Feature: vol_of_vol\n",
      "             mean       std       min       max\n",
      "cluster                                        \n",
      "0        0.000110  0.000031  0.000044  0.000192\n",
      "1        0.000246  0.000068  0.000128  0.000452\n",
      "2        0.000039       NaN  0.000039  0.000039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4g/_bw21mp523gbjm4t91xh0wp00000gn/T/ipykernel_80070/3351335454.py:136: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='cluster', y=feature, data=clustering_df, palette='viridis')\n",
      "/var/folders/4g/_bw21mp523gbjm4t91xh0wp00000gn/T/ipykernel_80070/3351335454.py:136: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='cluster', y=feature, data=clustering_df, palette='viridis')\n",
      "/var/folders/4g/_bw21mp523gbjm4t91xh0wp00000gn/T/ipykernel_80070/3351335454.py:136: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='cluster', y=feature, data=clustering_df, palette='viridis')\n",
      "/var/folders/4g/_bw21mp523gbjm4t91xh0wp00000gn/T/ipykernel_80070/3351335454.py:136: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='cluster', y=feature, data=clustering_df, palette='viridis')\n",
      "/var/folders/4g/_bw21mp523gbjm4t91xh0wp00000gn/T/ipykernel_80070/3351335454.py:136: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='cluster', y=feature, data=clustering_df, palette='viridis')\n",
      "/var/folders/4g/_bw21mp523gbjm4t91xh0wp00000gn/T/ipykernel_80070/3351335454.py:136: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.boxplot(x='cluster', y=feature, data=clustering_df, palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating ARMA-GARCH feature relationship matrix...\n",
      "\n",
      "--- ARMA-GARCH SUITABILITY BY CLUSTER ---\n",
      "Raw ARMA-GARCH suitability scores by cluster:\n",
      "         inv_serial_corr  inv_arch_effect  acf_lag1  sq_acf_lag1  \\\n",
      "cluster                                                            \n",
      "0               0.999997              1.0  0.121271     0.182128   \n",
      "1               1.000000              1.0  0.198246     0.195714   \n",
      "2               0.979272              1.0  0.000635     0.311566   \n",
      "\n",
      "         excess_kurtosis  vol_of_vol  \n",
      "cluster                               \n",
      "0              27.407550    0.000110  \n",
      "1              28.175342    0.000246  \n",
      "2              23.841924    0.000039  \n",
      "\n",
      "Normalized ARMA-GARCH suitability scores by cluster:\n",
      "         inv_serial_corr  inv_arch_effect  acf_lag1  sq_acf_lag1  \\\n",
      "cluster                                                            \n",
      "0               0.999877              NaN   0.61047     0.000000   \n",
      "1               1.000000              NaN   1.00000     0.104961   \n",
      "2               0.000000              NaN   0.00000     1.000000   \n",
      "\n",
      "         excess_kurtosis  vol_of_vol  arma_garch_score  \n",
      "cluster                                                 \n",
      "0               0.822821    0.344226          0.555479  \n",
      "1               1.000000    1.000000          0.820992  \n",
      "2               0.000000    0.000000          0.200000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4g/_bw21mp523gbjm4t91xh0wp00000gn/T/ipykernel_80070/3351335454.py:188: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=normalized_scores.index, y=normalized_scores['arma_garch_score'], palette='viridis')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The most suitable cluster for ARMA-GARCH modeling is Cluster 1\n",
      "ARMA-GARCH suitability score: 0.8210\n",
      "Stocks in this cluster: [94, 103, 0, 60, 9, 78, 8, 112, 102, 37, 27, 55, 126, 18, 100, 97, 87, 3, 11, 62, 72, 118, 33, 23, 58, 83, 114, 66, 6, 115, 82, 22, 40, 16, 4, 90, 80, 30, 98, 88, 17, 5, 75, 116, 38]\n",
      "Total number of stocks in Cluster 1: 45\n",
      "\n",
      "All visualizations have been saved to the current directory.\n",
      "Clustered data saved to arma_garch_clusters.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming clustering_df is your dataframe with ARMA-GARCH features\n",
    "# If you're running this separately, load the saved CSV:\n",
    "clustering_df = pd.read_csv(\"arma_garch_features.csv\")\n",
    "\n",
    "# Save stock_ids and drop from clustering features\n",
    "stock_ids = clustering_df['stock_id'].copy()\n",
    "features_for_clustering = clustering_df.drop('stock_id', axis=1).copy()\n",
    "\n",
    "# Handle any remaining NaN values\n",
    "features_for_clustering = features_for_clustering.fillna(0)\n",
    "\n",
    "# Scale the features for clustering and visualization\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_for_clustering)\n",
    "scaled_df = pd.DataFrame(scaled_features, columns=features_for_clustering.columns)\n",
    "\n",
    "# Perform K-means clustering if not done already\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Find optimal number of clusters\n",
    "print(\"\\n--- FINDING OPTIMAL NUMBER OF CLUSTERS ---\")\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 11)\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(scaled_features)\n",
    "    silhouette_avg = silhouette_score(scaled_features, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {k}, the silhouette score is {silhouette_avg}\")\n",
    "\n",
    "# Use optimal number of clusters\n",
    "best_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"\\nBest number of clusters: {best_k}\")\n",
    "\n",
    "# Final clustering with best_k\n",
    "kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "cluster_labels = kmeans.fit_predict(scaled_features)\n",
    "\n",
    "# Add cluster assignments back to the dataframe\n",
    "clustering_df['cluster'] = cluster_labels\n",
    "\n",
    "# Print cluster distribution\n",
    "print(\"\\n--- CLUSTER DISTRIBUTION ---\")\n",
    "cluster_counts = clustering_df['cluster'].value_counts().sort_index()\n",
    "for cluster, count in cluster_counts.items():\n",
    "    print(f\"Cluster {cluster}: {count} stocks\")\n",
    "\n",
    "# Create visualizations\n",
    "print(\"\\n--- CREATING VISUALIZATIONS ---\")\n",
    "\n",
    "# 1. Silhouette score plot\n",
    "print(\"Generating silhouette score plot...\")\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, silhouette_scores, 'o-', color='#3498db', linewidth=2, markersize=8)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.xlabel('Number of Clusters', fontsize=12)\n",
    "plt.ylabel('Silhouette Score', fontsize=12)\n",
    "plt.title('Optimal Number of Clusters', fontsize=14)\n",
    "plt.xticks(k_range)\n",
    "plt.savefig('silhouette_scores.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 2. PCA visualization\n",
    "print(\"Performing PCA and visualizing clusters...\")\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(scaled_features)\n",
    "\n",
    "# Print variance explained by PCA components\n",
    "print(f\"PCA Component 1 explains {pca.explained_variance_ratio_[0]:.2%} of variance\")\n",
    "print(f\"PCA Component 2 explains {pca.explained_variance_ratio_[1]:.2%} of variance\")\n",
    "print(f\"Total variance explained: {sum(pca.explained_variance_ratio_[:2]):.2%}\")\n",
    "\n",
    "# Create dataframe for plotting\n",
    "pca_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "pca_df['cluster'] = cluster_labels\n",
    "pca_df['stock_id'] = stock_ids.values\n",
    "\n",
    "# Plot PCA\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.scatterplot(x='PC1', y='PC2', hue='cluster', data=pca_df, palette='viridis', \n",
    "                s=100, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "plt.title('Stock Clusters Based on ARMA-GARCH Features', fontsize=16)\n",
    "plt.xlabel(f'Principal Component 1 ({pca.explained_variance_ratio_[0]:.2%} variance)', fontsize=12)\n",
    "plt.ylabel(f'Principal Component 2 ({pca.explained_variance_ratio_[1]:.2%} variance)', fontsize=12)\n",
    "plt.legend(title='Cluster', title_fontsize=12)\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.savefig('pca_arma_garch_clusters.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 3. Feature importance for clusters\n",
    "print(\"\\n--- CLUSTER CENTERS ---\")\n",
    "# Get cluster centers and calculate feature importance\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "feature_names = features_for_clustering.columns\n",
    "\n",
    "# Print cluster centers\n",
    "centers_df = pd.DataFrame(cluster_centers, columns=feature_names)\n",
    "centers_df.index = [f'Cluster {i}' for i in range(best_k)]\n",
    "print(centers_df)\n",
    "\n",
    "# Heatmap of cluster centers\n",
    "plt.figure(figsize=(16, 8))\n",
    "sns.heatmap(centers_df, annot=True, cmap='coolwarm', linewidths=.5, fmt='.2f')\n",
    "plt.title('ARMA-GARCH Feature Values by Cluster', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.savefig('cluster_centers_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 4. ARMA-GARCH specific features comparison\n",
    "print(\"\\n--- KEY ARMA-GARCH FEATURES BY CLUSTER ---\")\n",
    "# Create focused plots for the most relevant ARMA-GARCH features\n",
    "arma_garch_features = [\n",
    "    'serial_corr_pvalue', 'arch_effect_pvalue', 'acf_lag1', \n",
    "    'sq_acf_lag1', 'excess_kurtosis', 'vol_of_vol'\n",
    "]\n",
    "\n",
    "# Print key features by cluster\n",
    "for feature in arma_garch_features:\n",
    "    print(f\"\\nFeature: {feature}\")\n",
    "    feature_by_cluster = clustering_df.groupby('cluster')[feature].agg(['mean', 'std', 'min', 'max'])\n",
    "    print(feature_by_cluster)\n",
    "\n",
    "# Plot box plots for key ARMA-GARCH features by cluster\n",
    "plt.figure(figsize=(16, 12))\n",
    "for i, feature in enumerate(arma_garch_features):\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    sns.boxplot(x='cluster', y=feature, data=clustering_df, palette='viridis')\n",
    "    plt.title(f'{feature} by Cluster', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.savefig('arma_garch_features_boxplots.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 5. Scatter plot matrix for ARMA-GARCH features\n",
    "print(\"\\nGenerating ARMA-GARCH feature relationship matrix...\")\n",
    "plt.figure(figsize=(15, 15))\n",
    "plot_df = clustering_df[arma_garch_features + ['cluster', 'stock_id']]\n",
    "scatter_matrix = sns.pairplot(plot_df, hue='cluster', palette='viridis', \n",
    "                             diag_kind='kde', plot_kws={'alpha': 0.6, 's': 60, 'edgecolor': 'white', 'linewidth': 0.5})\n",
    "scatter_matrix.fig.suptitle('ARMA-GARCH Feature Relationships', y=1.02, fontsize=16)\n",
    "plt.savefig('arma_garch_feature_matrix.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# 6. Best cluster for ARMA-GARCH identification\n",
    "print(\"\\n--- ARMA-GARCH SUITABILITY BY CLUSTER ---\")\n",
    "# Calculate an \"ARMA-GARCH suitability score\" for each cluster\n",
    "# Lower p-values for serial correlation and ARCH effects are better\n",
    "# Higher values for ACF, squared ACF, and kurtosis suggest better ARMA-GARCH fit\n",
    "\n",
    "# First invert the p-values so higher is better\n",
    "clustering_df['inv_serial_corr'] = 1 - clustering_df['serial_corr_pvalue']\n",
    "clustering_df['inv_arch_effect'] = 1 - clustering_df['arch_effect_pvalue']\n",
    "\n",
    "# Calculate mean values by cluster\n",
    "cluster_scores = clustering_df.groupby('cluster').agg({\n",
    "    'inv_serial_corr': 'mean',\n",
    "    'inv_arch_effect': 'mean',\n",
    "    'acf_lag1': lambda x: np.abs(x).mean(),  # Use absolute value as both negative and positive autocorrelation matter\n",
    "    'sq_acf_lag1': lambda x: np.abs(x).mean(),\n",
    "    'excess_kurtosis': 'mean',\n",
    "    'vol_of_vol': 'mean'\n",
    "})\n",
    "\n",
    "# Print raw scores\n",
    "print(\"Raw ARMA-GARCH suitability scores by cluster:\")\n",
    "print(cluster_scores)\n",
    "\n",
    "# Normalize each feature to 0-1\n",
    "normalized_scores = (cluster_scores - cluster_scores.min()) / (cluster_scores.max() - cluster_scores.min())\n",
    "normalized_scores['arma_garch_score'] = normalized_scores.mean(axis=1)\n",
    "\n",
    "# Print normalized scores\n",
    "print(\"\\nNormalized ARMA-GARCH suitability scores by cluster:\")\n",
    "print(normalized_scores)\n",
    "\n",
    "# Plot the ARMA-GARCH suitability score by cluster\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=normalized_scores.index, y=normalized_scores['arma_garch_score'], palette='viridis')\n",
    "plt.axhline(y=normalized_scores['arma_garch_score'].mean(), color='red', linestyle='--', label='Average Score')\n",
    "plt.xticks([i for i in range(best_k)], [f'Cluster {i}' for i in range(best_k)])\n",
    "plt.xlabel('Cluster', fontsize=12)\n",
    "plt.ylabel('ARMA-GARCH Suitability Score', fontsize=12)\n",
    "plt.title('Cluster Suitability for ARMA-GARCH Modeling', fontsize=14)\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.3)\n",
    "plt.savefig('arma_garch_suitability_score.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "# Print the best cluster for ARMA-GARCH modeling\n",
    "best_cluster = normalized_scores['arma_garch_score'].idxmax()\n",
    "print(f\"\\nThe most suitable cluster for ARMA-GARCH modeling is Cluster {best_cluster}\")\n",
    "print(f\"ARMA-GARCH suitability score: {normalized_scores.loc[best_cluster, 'arma_garch_score']:.4f}\")\n",
    "\n",
    "# Print stocks in the best cluster\n",
    "stocks_in_best_cluster = clustering_df[clustering_df['cluster'] == best_cluster]['stock_id'].tolist()\n",
    "print(f\"Stocks in this cluster: {stocks_in_best_cluster}\")\n",
    "\n",
    "# Print total number of stocks in the best cluster\n",
    "print(f\"Total number of stocks in Cluster {best_cluster}: {len(stocks_in_best_cluster)}\")\n",
    "\n",
    "# 7. Save the final clustered data\n",
    "clustering_df.to_csv(\"arma_garch_clusters.csv\")\n",
    "print(\"\\nAll visualizations have been saved to the current directory.\")\n",
    "print(\"Clustered data saved to arma_garch_clusters.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacc2e5c",
   "metadata": {},
   "source": [
    "### ARMA-Garch fails to converge for different this data\n",
    "### Next steps: Diagnostics were run to understand why it does not work\n",
    "### AR - EWMA was deemed suitable and ran successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "471ecd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Cluster 1\n",
      "  Stock 94\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 94\n",
      "  Stock 103\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 103\n",
      "  Stock 0\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 0\n",
      "  Stock 60\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 60\n",
      "  Stock 9\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 9\n",
      "  Stock 78\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 78\n",
      "  Stock 8\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 8\n",
      "  Stock 112\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 112\n",
      "  Stock 102\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 102\n",
      "  Stock 37\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 37\n",
      "  Stock 27\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 27\n",
      "  Stock 55\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 55\n",
      "  Stock 126\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 126\n",
      "  Stock 18\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 18\n",
      "  Stock 100\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 100\n",
      "  Stock 97\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 97\n",
      "  Stock 87\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 87\n",
      "  Stock 3\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 3\n",
      "  Stock 11\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 11\n",
      "  Stock 62\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 62\n",
      "  Stock 72\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 72\n",
      "  Stock 118\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 118\n",
      "  Stock 33\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 33\n",
      "  Stock 23\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 23\n",
      "  Stock 58\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 58\n",
      "  Stock 83\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 83\n",
      "  Stock 114\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 114\n",
      "  Stock 66\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 66\n",
      "  Stock 6\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 6\n",
      "  Stock 115\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 115\n",
      "  Stock 82\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 82\n",
      "  Stock 22\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 22\n",
      "  Stock 40\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 40\n",
      "  Stock 16\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 16\n",
      "  Stock 4\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 4\n",
      "  Stock 90\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 90\n",
      "  Stock 80\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 80\n",
      "  Stock 30\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 30\n",
      "  Stock 98\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 98\n",
      "  Stock 88\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 88\n",
      "  Stock 17\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 17\n",
      "  Stock 5\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 5\n",
      "  Stock 75\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 75\n",
      "  Stock 116\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 116\n",
      "  Stock 38\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 38\n",
      "\n",
      "Processing Cluster 0\n",
      "  Stock 84\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 84\n",
      "  Stock 113\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 113\n",
      "  Stock 70\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 70\n",
      "  Stock 56\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 56\n",
      "  Stock 46\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 46\n",
      "  Stock 34\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 34\n",
      "  Stock 69\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 69\n",
      "  Stock 125\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 125\n",
      "  Stock 47\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 47\n",
      "  Stock 35\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 35\n",
      "  Stock 68\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 68\n",
      "  Stock 124\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 124\n",
      "  Stock 85\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 85\n",
      "  Stock 95\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 95\n",
      "  Stock 13\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 13\n",
      "  Stock 61\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 61\n",
      "  Stock 1\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 1\n",
      "  Stock 119\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 119\n",
      "  Stock 109\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 109\n",
      "  Stock 110\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 110\n",
      "  Stock 73\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 73\n",
      "  Stock 63\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 63\n",
      "  Stock 86\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 86\n",
      "  Stock 96\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 96\n",
      "  Stock 111\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 111\n",
      "  Stock 101\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 101\n",
      "  Stock 2\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 2\n",
      "  Stock 10\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 10\n",
      "  Stock 26\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 26\n",
      "  Stock 108\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 108\n",
      "  Stock 36\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 36\n",
      "  Stock 44\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 44\n",
      "  Stock 19\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 19\n",
      "  Stock 122\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 122\n",
      "  Stock 51\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 51\n",
      "  Stock 41\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 41\n",
      "  Stock 7\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 7\n",
      "  Stock 77\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 77\n",
      "  Stock 67\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 67\n",
      "  Stock 15\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 15\n",
      "  Stock 48\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 48\n",
      "  Stock 93\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 93\n",
      "  Stock 104\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 104\n",
      "  Stock 76\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 76\n",
      "  Stock 14\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 14\n",
      "  Stock 59\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 59\n",
      "  Stock 105\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 105\n",
      "  Stock 123\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 123\n",
      "  Stock 32\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 32\n",
      "  Stock 50\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 50\n",
      "  Stock 74\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 74\n",
      "  Stock 64\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 64\n",
      "  Stock 29\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 29\n",
      "  Stock 107\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 107\n",
      "  Stock 39\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 39\n",
      "  Stock 52\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 52\n",
      "  Stock 42\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 42\n",
      "  Stock 20\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 20\n",
      "  Stock 89\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 89\n",
      "  Stock 99\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 99\n",
      "  Stock 120\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 120\n",
      "  Stock 53\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 53\n",
      "  Stock 21\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 21\n",
      "  Stock 31\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 31\n",
      "  Stock 81\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 81\n",
      "  Stock 28\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 28\n",
      "\n",
      "Processing Cluster 2\n",
      "  Stock 43\n",
      "    Failed to fit AR(1)-GARCH(1,1)\n",
      "    Failed to fit Constant-GARCH(1,1)\n",
      "    Failed to fit AR(1)-ARCH(1)\n",
      "    All model configurations failed for stock 43\n",
      "\n",
      "Convergence Statistics: 0/112 models converged (0.0%)\n",
      "\n",
      "Model Type Statistics:\n",
      "  model_type  count\n",
      "0     failed    112\n",
      "\n",
      "No models converged successfully for any stocks\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from arch import arch_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the clustered data\n",
    "clustered_data = pd.read_csv(\"arma_garch_clusters.csv\")\n",
    "\n",
    "# Directory containing parquet files\n",
    "parquet_dir = \".\"\n",
    "\n",
    "# Selected time_ids from your code\n",
    "selected_time_ids = [5, 335, 697, 1107, 1326, 1640, 1938, 2178, 2479, 2833, 3113, 3469, 3877, 4138, 4460, 4743, 5101, 5407, 5729, 5978, 6325, 6643, 6930, 7245, 7629, 7921, 8441, 8718, 9091, 9367, 9819, 10100, 10491, 10781, 11070, 11431, 11764, 12030, 12348, 12661, 12965, 13318, 13579, 13868, 14176, 14452, 14795, 15038, 15418, 15728, 15989, 16404, 16704, 17029, 17305, 17606, 17914, 18184, 18502, 18836, 19157, 19488, 19747, 20135, 20460, 20827, 21145, 21507, 21891, 22249, 22622, 22922, 23220, 23531, 23863, 24224, 24707, 25059, 25347, 25636, 25924, 26307, 26603, 26944, 27240, 27595, 27964, 28379, 28801, 29171, 29590, 29941, 30313, 30624, 31047, 31322, 31609, 32083, 32463, 32767]\n",
    "\n",
    "# Calculate QLIKE function\n",
    "def calculate_qlike(actual_variance, predicted_variance):\n",
    "    \"\"\"Calculate QLIKE loss for volatility forecasts\"\"\"\n",
    "    predicted_variance = np.maximum(predicted_variance, 1e-6)  # Avoid division by zero\n",
    "    return actual_variance/predicted_variance - np.log(actual_variance/predicted_variance) - 1\n",
    "\n",
    "# Results storage\n",
    "results = {\n",
    "    'cluster': [],\n",
    "    'stock_id': [],\n",
    "    'mse': [],\n",
    "    'qlike': [],\n",
    "    'converged': [],\n",
    "    'model_type': []\n",
    "}\n",
    "\n",
    "# Process each cluster\n",
    "for cluster in clustered_data['cluster'].unique():\n",
    "    print(f\"\\nProcessing Cluster {cluster}\")\n",
    "    \n",
    "    # Get stocks in this cluster\n",
    "    cluster_stocks = clustered_data[clustered_data['cluster'] == cluster]['stock_id'].unique()\n",
    "    \n",
    "    # Process each stock in the cluster\n",
    "    for stock_id in cluster_stocks:\n",
    "        print(f\"  Stock {stock_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Load stock data from parquet file\n",
    "            file_path = os.path.join(parquet_dir, f\"stock_{stock_id}.parquet\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"    File not found for stock {stock_id}\")\n",
    "                continue\n",
    "                \n",
    "            # Read the parquet file and filter for selected time_ids\n",
    "            df = pd.read_parquet(file_path)\n",
    "            df = df[df['time_id'].isin(selected_time_ids)]\n",
    "            \n",
    "            # Sort and get returns\n",
    "            df = df.sort_values(['time_id', 'seconds_in_bucket'])\n",
    "            returns = df['log_return'].dropna().values\n",
    "            \n",
    "            if len(returns) < 100:\n",
    "                print(f\"    Insufficient data for stock {stock_id}\")\n",
    "                continue\n",
    "                \n",
    "            # Only mild preprocessing - trim extreme outliers that can destabilize GARCH\n",
    "            # Without changing the distribution characteristics too much\n",
    "            lower_bound = np.percentile(returns, 0.5)\n",
    "            upper_bound = np.percentile(returns, 99.5)\n",
    "            returns_clean = np.clip(returns, lower_bound, upper_bound)\n",
    "            \n",
    "            # Split into train (80%) and test (20%)\n",
    "            split = int(len(returns_clean) * 0.8)\n",
    "            train = returns_clean[:split]\n",
    "            test = returns_clean[split:]\n",
    "            \n",
    "            # List of model configurations to try\n",
    "            model_configs = [\n",
    "                # Standard AR(1)-GARCH(1,1) - try first\n",
    "                {'name': 'AR(1)-GARCH(1,1)', 'spec': {'mean': 'AR', 'lags': 1, 'vol': 'GARCH', 'p': 1, 'q': 1}},\n",
    "                # Try with constant mean if AR fails\n",
    "                {'name': 'Constant-GARCH(1,1)', 'spec': {'mean': 'Constant', 'vol': 'GARCH', 'p': 1, 'q': 1}},\n",
    "                # Try simpler ARCH model if GARCH fails\n",
    "                {'name': 'AR(1)-ARCH(1)', 'spec': {'mean': 'AR', 'lags': 1, 'vol': 'ARCH', 'p': 1}},\n",
    "            ]\n",
    "            \n",
    "            success = False\n",
    "            best_result = None\n",
    "            used_model = None\n",
    "            \n",
    "            # Try different model specifications\n",
    "            for config in model_configs:\n",
    "                if success:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    # Create model with current specification\n",
    "                    model = arch_model(train, **config['spec'])\n",
    "                    \n",
    "                    # First try with default settings\n",
    "                    try:\n",
    "                        result = model.fit(disp='off', show_warning=False)\n",
    "                        \n",
    "                        # Check if converged with reasonable parameters\n",
    "                        if result.convergence_status == 0:\n",
    "                            success = True\n",
    "                            best_result = result\n",
    "                            used_model = config['name']\n",
    "                            print(f\"    Successfully fit {config['name']} model\")\n",
    "                            break\n",
    "                    except:\n",
    "                        # If default settings fail, try with more iterations\n",
    "                        try:\n",
    "                            result = model.fit(disp='off', options={'maxiter': 1000}, show_warning=False)\n",
    "                            \n",
    "                            # Check if converged with this attempt\n",
    "                            if result.convergence_status == 0:\n",
    "                                success = True\n",
    "                                best_result = result\n",
    "                                used_model = config['name']\n",
    "                                print(f\"    Successfully fit {config['name']} model with more iterations\")\n",
    "                                break\n",
    "                        except:\n",
    "                            # Continue to next model configuration\n",
    "                            print(f\"    Failed to fit {config['name']}\")\n",
    "                            continue\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"    Error with {config['name']} model: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # If no model converged\n",
    "            if not success:\n",
    "                print(f\"    All model configurations failed for stock {stock_id}\")\n",
    "                results['cluster'].append(cluster)\n",
    "                results['stock_id'].append(stock_id)\n",
    "                results['mse'].append(np.nan)\n",
    "                results['qlike'].append(np.nan)\n",
    "                results['converged'].append(False)\n",
    "                results['model_type'].append(\"failed\")\n",
    "                continue\n",
    "                \n",
    "            # Make forecasts with the successful model\n",
    "            try:\n",
    "                forecasts = best_result.forecast(horizon=len(test))\n",
    "                \n",
    "                # Get predicted returns and volatility\n",
    "                pred_returns = forecasts.mean.values[-1, :]\n",
    "                pred_variance = forecasts.variance.values[-1, :]\n",
    "                \n",
    "                # Calculate metrics\n",
    "                mse = mean_squared_error(test, pred_returns)\n",
    "                \n",
    "                # Use squared returns as proxy for actual variance\n",
    "                actual_variance = test**2\n",
    "                qlike = np.mean(calculate_qlike(actual_variance, pred_variance))\n",
    "                \n",
    "                # Store results\n",
    "                results['cluster'].append(cluster)\n",
    "                results['stock_id'].append(stock_id)\n",
    "                results['mse'].append(mse)\n",
    "                results['qlike'].append(qlike)\n",
    "                results['converged'].append(True)\n",
    "                results['model_type'].append(used_model)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Error forecasting for stock {stock_id}: {str(e)}\")\n",
    "                results['cluster'].append(cluster)\n",
    "                results['stock_id'].append(stock_id)\n",
    "                results['mse'].append(np.nan)\n",
    "                results['qlike'].append(np.nan)\n",
    "                results['converged'].append(False)\n",
    "                results['model_type'].append(f\"{used_model}-forecast_failed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing stock {stock_id}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print convergence statistics\n",
    "converged_count = results_df['converged'].sum()\n",
    "total_count = len(results_df)\n",
    "print(f\"\\nConvergence Statistics: {converged_count}/{total_count} models converged ({converged_count/total_count*100:.1f}%)\")\n",
    "\n",
    "# Print model type statistics\n",
    "model_stats = results_df.groupby('model_type').size().reset_index(name='count')\n",
    "print(\"\\nModel Type Statistics:\")\n",
    "print(model_stats)\n",
    "\n",
    "# Calculate cluster-level metrics (only for converged models)\n",
    "successful_results = results_df[results_df['converged']].copy()\n",
    "\n",
    "if len(successful_results) > 0:\n",
    "    # Calculate metrics by cluster\n",
    "    cluster_summary = successful_results.groupby('cluster').agg({\n",
    "        'mse': ['mean', 'std', 'count'],\n",
    "        'qlike': ['mean', 'std', 'count']\n",
    "    })\n",
    "    \n",
    "    # Add convergence rate\n",
    "    convergence_by_cluster = pd.DataFrame({\n",
    "        'total': results_df.groupby('cluster').size(),\n",
    "        'converged': results_df[results_df['converged']].groupby('cluster').size()\n",
    "    }).fillna(0)\n",
    "    \n",
    "    convergence_by_cluster['rate'] = convergence_by_cluster['converged'] / convergence_by_cluster['total']\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n--- Cluster Performance Summary ---\")\n",
    "    print(cluster_summary)\n",
    "    \n",
    "    print(\"\\n--- Convergence by Cluster ---\")\n",
    "    print(convergence_by_cluster)\n",
    "    \n",
    "    # Find best clusters\n",
    "    if not cluster_summary['mse']['mean'].isna().all():\n",
    "        best_mse_cluster = cluster_summary['mse']['mean'].idxmin()\n",
    "        print(f\"\\nBest cluster by MSE: Cluster {best_mse_cluster}\")\n",
    "    \n",
    "    if not cluster_summary['qlike']['mean'].isna().all():\n",
    "        best_qlike_cluster = cluster_summary['qlike']['mean'].idxmin()\n",
    "        print(f\"Best cluster by QLIKE: Cluster {best_qlike_cluster}\")\n",
    "else:\n",
    "    print(\"\\nNo models converged successfully for any stocks\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(\"arma_garch_metrics_by_stock.csv\", index=False)\n",
    "if len(successful_results) > 0:\n",
    "    cluster_summary.to_csv(\"arma_garch_metrics_by_cluster.csv\")\n",
    "    convergence_by_cluster.to_csv(\"arma_garch_convergence_by_cluster.csv\")\n",
    "    \n",
    "    # Save successful results separately\n",
    "    successful_results.to_csv(\"arma_garch_successful_models.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f160abe0",
   "metadata": {},
   "source": [
    "#### Diagnostic analysis to understand why ARMA-Garch is not suitable:\n",
    "- #### Inequality constraints are incompatible\n",
    "- #### High percentage of zero returns \n",
    "- #### Extreme outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beda525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== STARTING DATA INSPECTION =====\n",
      "\n",
      "Sample stock 94 data columns: ['time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_price2', 'ask_price2', 'bid_size1', 'ask_size1', 'bid_size2', 'ask_size2', 'stock_id', 'WAP', 'BidAskSpread', 'log_return', 'time_bucket', 'volatility']\n",
      "Sample rows:\n",
      "   time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  ask_price2  \\\n",
      "0        5                  0    1.000301    1.000903    1.000129    1.000989   \n",
      "1        5                  3    1.000301    1.000903    1.000129    1.000989   \n",
      "2        5                  4    1.000301    1.000903    1.000043    1.000989   \n",
      "\n",
      "   bid_size1  ask_size1  bid_size2  ask_size2  stock_id       WAP  \\\n",
      "0        101         60        101         10        94  1.000679   \n",
      "1        101         60        101         10        94  1.000679   \n",
      "2        101         71          1         10        94  1.000655   \n",
      "\n",
      "   BidAskSpread  log_return  time_bucket  volatility  \n",
      "0      0.000602         NaN            0         NaN  \n",
      "1      0.000602    0.000000            1    0.000733  \n",
      "2      0.000602   -0.000024            1    0.000733  \n",
      "Found 100 unique time_ids out of 100 expected\n",
      "\n",
      "----- DIAGNOSTICS FOR STOCK 94 -----\n",
      "Data shape: (29983,)\n",
      "Missing values: 0\n",
      "Mean: 1.502433287057717e-06\n",
      "Std Dev: 0.0003243673559313733\n",
      "Min: -0.003784021890529171\n",
      "Max: 0.005988216092688867\n",
      "5% of zeros: 18.38%\n",
      "First 10 values: [ 0.00000000e+00 -2.41400932e-05 -3.28816628e-04  1.84295441e-05\n",
      "  4.01698614e-04 -1.77162188e-04  2.53427022e-04  0.00000000e+00\n",
      "  5.00462095e-08  0.00000000e+00]\n",
      "Extreme outliers: 2647 (8.83%)\n",
      "Volatility clustering (lag-1 correlation of squared returns): 0.1929\n",
      "\n",
      "Sample stock 84 data columns: ['time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_price2', 'ask_price2', 'bid_size1', 'ask_size1', 'bid_size2', 'ask_size2', 'stock_id', 'WAP', 'BidAskSpread', 'log_return', 'time_bucket', 'volatility']\n",
      "Sample rows:\n",
      "   time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  ask_price2  \\\n",
      "0        5                  0    1.001911    1.002451    1.001872    1.002490   \n",
      "1        5                  1    1.002027    1.002490    1.001988    1.002567   \n",
      "2        5                  2    1.001911    1.002258    1.001795    1.002374   \n",
      "\n",
      "   bid_size1  ask_size1  bid_size2  ask_size2  stock_id       WAP  \\\n",
      "0          1         25         25         26        84  1.001932   \n",
      "1         25          1         25         25        84  1.002472   \n",
      "2          1        100          1         25        84  1.001914   \n",
      "\n",
      "   BidAskSpread  log_return  time_bucket  volatility  \n",
      "0      0.000539         NaN            0         NaN  \n",
      "1      0.000462    0.000539            1     0.00156  \n",
      "2      0.000347   -0.000557            1     0.00156  \n",
      "Found 100 unique time_ids out of 100 expected\n",
      "\n",
      "----- DIAGNOSTICS FOR STOCK 84 -----\n",
      "Data shape: (50861,)\n",
      "Missing values: 0\n",
      "Mean: 5.943105356203713e-07\n",
      "Std Dev: 0.00021218476551753472\n",
      "Min: -0.003329299579731114\n",
      "Max: 0.003036033216694716\n",
      "5% of zeros: 12.76%\n",
      "First 10 values: [ 5.39308644e-04 -5.56623215e-04  5.48724761e-04  3.66714691e-06\n",
      "  8.34778833e-05  1.01754917e-04 -1.24726817e-04 -2.24040468e-04\n",
      " -3.03736627e-05  5.62487557e-04]\n",
      "Extreme outliers: 2605 (5.12%)\n",
      "Volatility clustering (lag-1 correlation of squared returns): 0.1957\n",
      "\n",
      "Sample stock 43 data columns: ['time_id', 'seconds_in_bucket', 'bid_price1', 'ask_price1', 'bid_price2', 'ask_price2', 'bid_size1', 'ask_size1', 'bid_size2', 'ask_size2', 'stock_id', 'WAP', 'BidAskSpread', 'log_return', 'time_bucket', 'volatility']\n",
      "Sample rows:\n",
      "   time_id  seconds_in_bucket  bid_price1  ask_price1  bid_price2  ask_price2  \\\n",
      "0        5                  0    0.999882    0.999934    0.999856    0.999961   \n",
      "1        5                  1    1.000013    1.000039    0.999987    1.000065   \n",
      "2        5                  2    0.999987    1.000039    0.999961    1.000065   \n",
      "\n",
      "   bid_size1  ask_size1  bid_size2  ask_size2  stock_id       WAP  \\\n",
      "0        955        355        818        589        43  0.999920   \n",
      "1        355        200       1555       1100        43  1.000030   \n",
      "2        855        355        355        655        43  1.000024   \n",
      "\n",
      "   BidAskSpread  log_return  time_bucket  volatility  \n",
      "0      0.000052         NaN            0         NaN  \n",
      "1      0.000026    0.000110            1    0.000569  \n",
      "2      0.000052   -0.000006            1    0.000569  \n",
      "Found 100 unique time_ids out of 100 expected\n",
      "\n",
      "----- DIAGNOSTICS FOR STOCK 43 -----\n",
      "Data shape: (59818,)\n",
      "Missing values: 0\n",
      "Mean: 4.820596669241585e-07\n",
      "Std Dev: 6.841781056779083e-05\n",
      "Min: -0.0012011549935655422\n",
      "Max: 0.001925020702498859\n",
      "5% of zeros: 1.95%\n",
      "First 10 values: [ 1.09545028e-04 -5.93195275e-06  1.06237554e-04  8.32556160e-05\n",
      "  2.31731576e-04  6.64566889e-05  1.48856070e-04 -1.10614859e-04\n",
      "  1.12986016e-04 -5.04334890e-05]\n",
      "Extreme outliers: 1917 (3.20%)\n",
      "Volatility clustering (lag-1 correlation of squared returns): 0.3116\n",
      "\n",
      "===== STARTING MODEL FITTING =====\n",
      "\n",
      "Processing Cluster 1\n",
      "  Stock 94\n",
      "\n",
      "----- DIAGNOSTICS FOR STOCK 94 -----\n",
      "Data shape: (29983,)\n",
      "Missing values: 0\n",
      "Mean: 1.502433287057717e-06\n",
      "Std Dev: 0.0003243673559313733\n",
      "Min: -0.003784021890529171\n",
      "Max: 0.005988216092688867\n",
      "5% of zeros: 18.38%\n",
      "First 10 values: [ 0.00000000e+00 -2.41400932e-05 -3.28816628e-04  1.84295441e-05\n",
      "  4.01698614e-04 -1.77162188e-04  2.53427022e-04  0.00000000e+00\n",
      "  5.00462095e-08  0.00000000e+00]\n",
      "Extreme outliers: 2647 (8.83%)\n",
      "Volatility clustering (lag-1 correlation of squared returns): 0.1929\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 94\n",
      "  Stock 103\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 103\n",
      "  Stock 0\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 0\n",
      "  Stock 60\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 60\n",
      "  Stock 9\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 9\n",
      "\n",
      "Processing Cluster 0\n",
      "  Stock 84\n",
      "\n",
      "----- DIAGNOSTICS FOR STOCK 84 -----\n",
      "Data shape: (50861,)\n",
      "Missing values: 0\n",
      "Mean: 5.943105356203713e-07\n",
      "Std Dev: 0.00021218476551753472\n",
      "Min: -0.003329299579731114\n",
      "Max: 0.003036033216694716\n",
      "5% of zeros: 12.76%\n",
      "First 10 values: [ 5.39308644e-04 -5.56623215e-04  5.48724761e-04  3.66714691e-06\n",
      "  8.34778833e-05  1.01754917e-04 -1.24726817e-04 -2.24040468e-04\n",
      " -3.03736627e-05  5.62487557e-04]\n",
      "Extreme outliers: 2605 (5.12%)\n",
      "Volatility clustering (lag-1 correlation of squared returns): 0.1957\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 84\n",
      "  Stock 113\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 113\n",
      "  Stock 70\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 70\n",
      "  Stock 56\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 56\n",
      "  Stock 46\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 46\n",
      "\n",
      "Processing Cluster 2\n",
      "  Stock 43\n",
      "\n",
      "----- DIAGNOSTICS FOR STOCK 43 -----\n",
      "Data shape: (59818,)\n",
      "Missing values: 0\n",
      "Mean: 4.820596669241585e-07\n",
      "Std Dev: 6.841781056779083e-05\n",
      "Min: -0.0012011549935655422\n",
      "Max: 0.001925020702498859\n",
      "5% of zeros: 1.95%\n",
      "First 10 values: [ 1.09545028e-04 -5.93195275e-06  1.06237554e-04  8.32556160e-05\n",
      "  2.31731576e-04  6.64566889e-05  1.48856070e-04 -1.10614859e-04\n",
      "  1.12986016e-04 -5.04334890e-05]\n",
      "Extreme outliers: 1917 (3.20%)\n",
      "Volatility clustering (lag-1 correlation of squared returns): 0.3116\n",
      "    Trying Constant-ARCH(1) model...\n",
      "    Error with Constant-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying Constant-GARCH(1,1) model...\n",
      "    Error with Constant-GARCH(1,1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    Trying AR(1)-ARCH(1) model...\n",
      "    Error with AR(1)-ARCH(1) model: 'ARCHModelResult' object has no attribute 'convergence_status'\n",
      "    All model configurations failed for stock 43\n",
      "\n",
      "Convergence Statistics: 0/11 models converged (0.0%)\n",
      "\n",
      "Model Type Statistics:\n",
      "  model_type  count\n",
      "0     failed     11\n",
      "\n",
      "No models converged successfully for any stocks\n",
      "\n",
      "===== RECOMMENDATIONS =====\n",
      "\n",
      "Based on the diagnostics, here are strategies to try:\n",
      "1. Use simpler models: Start with ARCH(1) with constant mean\n",
      "2. If volatility clustering is weak, consider just using AR models without GARCH\n",
      "3. For extreme data, try using a Student's t distribution instead of normal\n",
      "4. Reduce the data requirements - work with fewer time periods\n",
      "5. Consider using a different volatility modeling approach like RiskMetrics (EWMA)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from arch import arch_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the clustered data\n",
    "clustered_data = pd.read_csv(\"arma_garch_clusters.csv\")\n",
    "\n",
    "# Directory containing parquet files\n",
    "parquet_dir = \".\"\n",
    "\n",
    "# Selected time_ids from your code\n",
    "selected_time_ids = [5, 335, 697, 1107, 1326, 1640, 1938, 2178, 2479, 2833, 3113, 3469, 3877, 4138, 4460, 4743, 5101, 5407, 5729, 5978, 6325, 6643, 6930, 7245, 7629, 7921, 8441, 8718, 9091, 9367, 9819, 10100, 10491, 10781, 11070, 11431, 11764, 12030, 12348, 12661, 12965, 13318, 13579, 13868, 14176, 14452, 14795, 15038, 15418, 15728, 15989, 16404, 16704, 17029, 17305, 17606, 17914, 18184, 18502, 18836, 19157, 19488, 19747, 20135, 20460, 20827, 21145, 21507, 21891, 22249, 22622, 22922, 23220, 23531, 23863, 24224, 24707, 25059, 25347, 25636, 25924, 26307, 26603, 26944, 27240, 27595, 27964, 28379, 28801, 29171, 29590, 29941, 30313, 30624, 31047, 31322, 31609, 32083, 32463, 32767]\n",
    "\n",
    "# Calculate QLIKE function\n",
    "def calculate_qlike(actual_variance, predicted_variance):\n",
    "    \"\"\"Calculate QLIKE loss for volatility forecasts\"\"\"\n",
    "    predicted_variance = np.maximum(predicted_variance, 1e-6)  # Avoid division by zero\n",
    "    return actual_variance/predicted_variance - np.log(actual_variance/predicted_variance) - 1\n",
    "\n",
    "# Function to diagnose data quality\n",
    "def diagnose_returns(returns, stock_id):\n",
    "    \"\"\"Print diagnostic information about returns series\"\"\"\n",
    "    print(f\"\\n----- DIAGNOSTICS FOR STOCK {stock_id} -----\")\n",
    "    print(f\"Data shape: {returns.shape}\")\n",
    "    \n",
    "    if len(returns) == 0:\n",
    "        print(\"ERROR: No data found\")\n",
    "        return False\n",
    "        \n",
    "    print(f\"Missing values: {np.isnan(returns).sum()}\")\n",
    "    print(f\"Mean: {np.mean(returns)}\")\n",
    "    print(f\"Std Dev: {np.std(returns)}\")\n",
    "    print(f\"Min: {np.min(returns)}\")\n",
    "    print(f\"Max: {np.max(returns)}\")\n",
    "    print(f\"5% of zeros: {np.sum(returns == 0) / len(returns) * 100:.2f}%\")\n",
    "    \n",
    "    # Print first few values\n",
    "    print(\"First 10 values:\", returns[:10])\n",
    "    \n",
    "    # Check for extreme outliers\n",
    "    q1 = np.percentile(returns, 25)\n",
    "    q3 = np.percentile(returns, 75)\n",
    "    iqr = q3 - q1\n",
    "    outliers = np.sum((returns < q1 - 3 * iqr) | (returns > q3 + 3 * iqr))\n",
    "    print(f\"Extreme outliers: {outliers} ({outliers/len(returns)*100:.2f}%)\")\n",
    "    \n",
    "    # Check for clustering of volatility (ARCH effects)\n",
    "    squared_returns = returns**2\n",
    "    lag_1_corr = np.corrcoef(squared_returns[:-1], squared_returns[1:])[0, 1]\n",
    "    print(f\"Volatility clustering (lag-1 correlation of squared returns): {lag_1_corr:.4f}\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Results storage\n",
    "results = {\n",
    "    'cluster': [],\n",
    "    'stock_id': [],\n",
    "    'mse': [],\n",
    "    'qlike': [],\n",
    "    'converged': [],\n",
    "    'model_type': []\n",
    "}\n",
    "\n",
    "# Process each cluster\n",
    "print(\"\\n===== STARTING DATA INSPECTION =====\")\n",
    "# Choose a sample stock for detailed diagnostics\n",
    "sample_stocks = []\n",
    "for cluster in clustered_data['cluster'].unique():\n",
    "    cluster_stocks = clustered_data[clustered_data['cluster'] == cluster]['stock_id'].unique()\n",
    "    if len(cluster_stocks) > 0:\n",
    "        sample_stocks.append(cluster_stocks[0])\n",
    "\n",
    "# Inspect a few sample stocks in detail\n",
    "for stock_id in sample_stocks[:3]:  # Look at first 3 stocks\n",
    "    try:\n",
    "        file_path = os.path.join(parquet_dir, f\"stock_{stock_id}.parquet\")\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_parquet(file_path)\n",
    "            df = df[df['time_id'].isin(selected_time_ids)]\n",
    "            \n",
    "            print(f\"\\nSample stock {stock_id} data columns: {df.columns.tolist()}\")\n",
    "            print(f\"Sample rows:\")\n",
    "            print(df.head(3))\n",
    "            \n",
    "            # Check time_id distribution\n",
    "            print(f\"Found {len(df['time_id'].unique())} unique time_ids out of {len(selected_time_ids)} expected\")\n",
    "            \n",
    "            if 'log_return' in df.columns:\n",
    "                returns = df['log_return'].dropna().values\n",
    "                diagnose_returns(returns, stock_id)\n",
    "            else:\n",
    "                print(f\"WARNING: 'log_return' column not found in stock {stock_id}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error inspecting stock {stock_id}: {str(e)}\")\n",
    "\n",
    "print(\"\\n===== STARTING MODEL FITTING =====\")\n",
    "\n",
    "# Set a flag to use simple models that are more likely to converge\n",
    "# This uses much simpler models that should converge more easily\n",
    "USE_SIMPLIFIED_MODELS = True\n",
    "\n",
    "# Process each cluster\n",
    "for cluster in clustered_data['cluster'].unique()[:3]:  # Start with just first 3 clusters\n",
    "    print(f\"\\nProcessing Cluster {cluster}\")\n",
    "    \n",
    "    # Get stocks in this cluster\n",
    "    cluster_stocks = clustered_data[clustered_data['cluster'] == cluster]['stock_id'].unique()\n",
    "    \n",
    "    # Process each stock in the cluster\n",
    "    for stock_id in cluster_stocks[:5]:  # Process just 5 stocks per cluster initially\n",
    "        print(f\"  Stock {stock_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Load stock data from parquet file\n",
    "            file_path = os.path.join(parquet_dir, f\"stock_{stock_id}.parquet\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"    File not found for stock {stock_id}\")\n",
    "                continue\n",
    "                \n",
    "            # Read the parquet file and filter for selected time_ids\n",
    "            df = pd.read_parquet(file_path)\n",
    "            df = df[df['time_id'].isin(selected_time_ids)]\n",
    "            \n",
    "            # Sort and get returns\n",
    "            df = df.sort_values(['time_id', 'seconds_in_bucket'])\n",
    "            returns = df['log_return'].dropna().values\n",
    "            \n",
    "            if len(returns) < 50:  # Reduced minimum length\n",
    "                print(f\"    Insufficient data for stock {stock_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Data diagnostics for the first stock in each cluster\n",
    "            if stock_id == cluster_stocks[0]:\n",
    "                diagnose_returns(returns, stock_id)\n",
    "                \n",
    "            # Split into train (80%) and test (20%)\n",
    "            split = int(len(returns) * 0.8)\n",
    "            train = returns[:split]\n",
    "            test = returns[split:]\n",
    "            \n",
    "            # Try to fit a VERY simple model first\n",
    "            success = False\n",
    "            best_result = None\n",
    "            used_model = None\n",
    "            \n",
    "            # List of model configurations to try - ordered from simplest to more complex\n",
    "            if USE_SIMPLIFIED_MODELS:\n",
    "                model_configs = [\n",
    "                    # Pure ARCH model with constant mean - extremely simple\n",
    "                    {'name': 'Constant-ARCH(1)', 'spec': {'mean': 'Constant', 'vol': 'ARCH', 'p': 1}},\n",
    "                    # Standard GARCH model with constant mean\n",
    "                    {'name': 'Constant-GARCH(1,1)', 'spec': {'mean': 'Constant', 'vol': 'GARCH', 'p': 1, 'q': 1}},\n",
    "                    # AR(1) mean model with ARCH volatility\n",
    "                    {'name': 'AR(1)-ARCH(1)', 'spec': {'mean': 'AR', 'lags': 1, 'vol': 'ARCH', 'p': 1}},\n",
    "                ]\n",
    "            else:\n",
    "                # Original model configurations\n",
    "                model_configs = [\n",
    "                    {'name': 'AR(1)-GARCH(1,1)', 'spec': {'mean': 'AR', 'lags': 1, 'vol': 'GARCH', 'p': 1, 'q': 1}},\n",
    "                    {'name': 'Constant-GARCH(1,1)', 'spec': {'mean': 'Constant', 'vol': 'GARCH', 'p': 1, 'q': 1}},\n",
    "                    {'name': 'AR(1)-ARCH(1)', 'spec': {'mean': 'AR', 'lags': 1, 'vol': 'ARCH', 'p': 1}},\n",
    "                ]\n",
    "            \n",
    "            # Try different model specifications\n",
    "            for config in model_configs:\n",
    "                if success:\n",
    "                    break\n",
    "                    \n",
    "                try:\n",
    "                    print(f\"    Trying {config['name']} model...\")\n",
    "                    # Create model with current specification\n",
    "                    model = arch_model(train, **config['spec'])\n",
    "                    \n",
    "                    # Turn on detailed display to see what's happening during convergence\n",
    "                    result = model.fit(disp='off', show_warning=False)\n",
    "                    convergence_status = result.convergence_status\n",
    "                    \n",
    "                    print(f\"    {config['name']} convergence status: {convergence_status}\")\n",
    "                    \n",
    "                    # Check convergence\n",
    "                    if convergence_status == 0:\n",
    "                        success = True\n",
    "                        best_result = result\n",
    "                        used_model = config['name']\n",
    "                        print(f\"    Successfully fit {config['name']} model\")\n",
    "                        break\n",
    "                    else:\n",
    "                        print(f\"    Model didn't converge. Trying next configuration.\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"    Error with {config['name']} model: {str(e)}\")\n",
    "                    continue\n",
    "            \n",
    "            # If no model converged\n",
    "            if not success:\n",
    "                print(f\"    All model configurations failed for stock {stock_id}\")\n",
    "                results['cluster'].append(cluster)\n",
    "                results['stock_id'].append(stock_id)\n",
    "                results['mse'].append(np.nan)\n",
    "                results['qlike'].append(np.nan)\n",
    "                results['converged'].append(False)\n",
    "                results['model_type'].append(\"failed\")\n",
    "                continue\n",
    "                \n",
    "            # Make forecasts with the successful model\n",
    "            try:\n",
    "                forecasts = best_result.forecast(horizon=len(test))\n",
    "                \n",
    "                # Get predicted returns and volatility\n",
    "                pred_returns = forecasts.mean.values[-1, :]\n",
    "                pred_variance = forecasts.variance.values[-1, :]\n",
    "                \n",
    "                # Calculate metrics\n",
    "                mse = mean_squared_error(test, pred_returns)\n",
    "                \n",
    "                # Use squared returns as proxy for actual variance\n",
    "                actual_variance = test**2\n",
    "                qlike = np.mean(calculate_qlike(actual_variance, pred_variance))\n",
    "                \n",
    "                # Store results\n",
    "                results['cluster'].append(cluster)\n",
    "                results['stock_id'].append(stock_id)\n",
    "                results['mse'].append(mse)\n",
    "                results['qlike'].append(qlike)\n",
    "                results['converged'].append(True)\n",
    "                results['model_type'].append(used_model)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    Error forecasting for stock {stock_id}: {str(e)}\")\n",
    "                results['cluster'].append(cluster)\n",
    "                results['stock_id'].append(stock_id)\n",
    "                results['mse'].append(np.nan)\n",
    "                results['qlike'].append(np.nan)\n",
    "                results['converged'].append(False)\n",
    "                results['model_type'].append(f\"{used_model}-forecast_failed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing stock {stock_id}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Print convergence statistics\n",
    "if len(results_df) > 0:\n",
    "    converged_count = results_df['converged'].sum()\n",
    "    total_count = len(results_df)\n",
    "    print(f\"\\nConvergence Statistics: {converged_count}/{total_count} models converged ({converged_count/total_count*100:.1f}%)\")\n",
    "\n",
    "    # Print model type statistics\n",
    "    model_stats = results_df.groupby('model_type').size().reset_index(name='count')\n",
    "    print(\"\\nModel Type Statistics:\")\n",
    "    print(model_stats)\n",
    "\n",
    "    # Calculate cluster-level metrics (only for converged models)\n",
    "    successful_results = results_df[results_df['converged']].copy()\n",
    "\n",
    "    if len(successful_results) > 0:\n",
    "        # Calculate metrics by cluster\n",
    "        cluster_summary = successful_results.groupby('cluster').agg({\n",
    "            'mse': ['mean', 'std', 'count'],\n",
    "            'qlike': ['mean', 'std', 'count']\n",
    "        })\n",
    "        \n",
    "        # Add convergence rate\n",
    "        convergence_by_cluster = pd.DataFrame({\n",
    "            'total': results_df.groupby('cluster').size(),\n",
    "            'converged': results_df[results_df['converged']].groupby('cluster').size()\n",
    "        }).fillna(0)\n",
    "        \n",
    "        convergence_by_cluster['rate'] = convergence_by_cluster['converged'] / convergence_by_cluster['total']\n",
    "        \n",
    "        # Print summary\n",
    "        print(\"\\n--- Cluster Performance Summary ---\")\n",
    "        print(cluster_summary)\n",
    "        \n",
    "        print(\"\\n--- Convergence by Cluster ---\")\n",
    "        print(convergence_by_cluster)\n",
    "        \n",
    "        # Find best clusters\n",
    "        if not cluster_summary['mse']['mean'].isna().all():\n",
    "            best_mse_cluster = cluster_summary['mse']['mean'].idxmin()\n",
    "            print(f\"\\nBest cluster by MSE: Cluster {best_mse_cluster}\")\n",
    "        \n",
    "        if not cluster_summary['qlike']['mean'].isna().all():\n",
    "            best_qlike_cluster = cluster_summary['qlike']['mean'].idxmin()\n",
    "            print(f\"Best cluster by QLIKE: Cluster {best_qlike_cluster}\")\n",
    "    else:\n",
    "        print(\"\\nNo models converged successfully for any stocks\")\n",
    "else:\n",
    "    print(\"\\nNo results were collected.\")\n",
    "\n",
    "print(\"\\n===== RECOMMENDATIONS =====\")\n",
    "print(\"\"\"\n",
    "Based on the diagnostics, here are strategies to try:\n",
    "1. Use simpler models: Start with ARCH(1) with constant mean\n",
    "2. If volatility clustering is weak, consider just using AR models without GARCH\n",
    "3. For extreme data, try using a Student's t distribution instead of normal\n",
    "4. Reduce the data requirements - work with fewer time periods\n",
    "5. Consider using a different volatility modeling approach like RiskMetrics (EWMA)\n",
    "\"\"\")\n",
    "\n",
    "# Save diagnostic version results\n",
    "if len(results_df) > 0:\n",
    "    results_df.to_csv(\"arma_garch_diagnostics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa6152f",
   "metadata": {},
   "source": [
    "#### AR-EWMA runs better on the current data regardless of clusters and stocks (no covergence issues). Almost all stock in clusters have convergence issues when using ARMA - Garch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3204b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Cluster 1\n",
      "  Stock 94\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 103\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 0\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 60\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 9\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 78\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 8\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 112\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 102\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 37\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 27\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 55\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 126\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 18\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 100\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 97\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 87\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 3\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 11\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 62\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 72\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 118\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 33\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 23\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 58\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 83\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 114\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 66\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 6\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 115\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 82\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 22\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 40\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 16\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 4\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 90\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 80\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 30\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 98\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 88\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 17\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 5\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 75\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 116\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 38\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "\n",
      "Processing Cluster 0\n",
      "  Stock 84\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 113\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 70\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 56\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 46\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 34\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 69\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 125\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 47\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 35\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 68\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 124\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 85\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 95\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 13\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 61\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 1\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 119\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 109\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 110\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 73\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 63\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 86\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 96\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 111\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 101\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 2\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 10\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 26\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 108\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 36\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 44\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 19\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 122\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 51\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 41\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 7\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 77\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 67\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 15\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 48\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 93\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 104\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 76\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 14\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 59\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 105\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 123\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 32\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 50\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 74\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 64\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 29\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 107\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 39\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 52\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 42\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 20\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 89\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 99\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 120\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 53\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 21\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 31\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 81\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "  Stock 28\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "\n",
      "Processing Cluster 2\n",
      "  Stock 43\n",
      "    Successfully modeled using AR(1)-EWMA\n",
      "\n",
      "Successfully modeled 112 stocks\n",
      "\n",
      "--- Cluster Performance Summary ---\n",
      "                  mse                     qlike          \n",
      "                 mean           std count  mean std count\n",
      "cluster                                                  \n",
      "0        3.249715e-08  1.690222e-08    66   inf NaN    66\n",
      "1        1.401260e-07  8.013220e-08    45   inf NaN    45\n",
      "2        4.949051e-09           NaN     1   inf NaN     1\n",
      "\n",
      "Best cluster by MSE: Cluster 2\n",
      "Best cluster by QLIKE: Cluster 0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from arch import arch_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load the clustered data\n",
    "clustered_data = pd.read_csv(\"arma_garch_clusters.csv\")\n",
    "\n",
    "# Directory containing parquet files\n",
    "parquet_dir = \".\"\n",
    "\n",
    "# Selected time_ids from your code\n",
    "selected_time_ids = [5, 335, 697, 1107, 1326, 1640, 1938, 2178, 2479, 2833, 3113, 3469, 3877, 4138, 4460, 4743, 5101, 5407, 5729, 5978, 6325, 6643, 6930, 7245, 7629, 7921, 8441, 8718, 9091, 9367, 9819, 10100, 10491, 10781, 11070, 11431, 11764, 12030, 12348, 12661, 12965, 13318, 13579, 13868, 14176, 14452, 14795, 15038, 15418, 15728, 15989, 16404, 16704, 17029, 17305, 17606, 17914, 18184, 18502, 18836, 19157, 19488, 19747, 20135, 20460, 20827, 21145, 21507, 21891, 22249, 22622, 22922, 23220, 23531, 23863, 24224, 24707, 25059, 25347, 25636, 25924, 26307, 26603, 26944, 27240, 27595, 27964, 28379, 28801, 29171, 29590, 29941, 30313, 30624, 31047, 31322, 31609, 32083, 32463, 32767]\n",
    "\n",
    "# Calculate QLIKE function\n",
    "def calculate_qlike(actual_variance, predicted_variance):\n",
    "    \"\"\"Calculate QLIKE loss for volatility forecasts\"\"\"\n",
    "    predicted_variance = np.maximum(predicted_variance, 1e-6)  # Avoid division by zero\n",
    "    return actual_variance/predicted_variance - np.log(actual_variance/predicted_variance) - 1\n",
    "\n",
    "# Function to compute EWMA volatility\n",
    "def calculate_ewma_variance(returns, lambda_param=0.94):\n",
    "    \"\"\"\n",
    "    Calculate EWMA (Exponentially Weighted Moving Average) variance\n",
    "    This is similar to RiskMetrics approach and more robust than GARCH for noisy data\n",
    "    \"\"\"\n",
    "    # Initialize variance with sample variance for first observation\n",
    "    n = len(returns)\n",
    "    variance = np.zeros(n)\n",
    "    \n",
    "    # Use first 20 observations to initialize\n",
    "    if n > 20:\n",
    "        variance[0] = np.var(returns[:20])\n",
    "    else:\n",
    "        variance[0] = returns[0]**2\n",
    "    \n",
    "    # Calculate EWMA variance\n",
    "    for t in range(1, n):\n",
    "        variance[t] = lambda_param * variance[t-1] + (1 - lambda_param) * returns[t-1]**2\n",
    "    \n",
    "    return variance\n",
    "\n",
    "# Function to fit a simple AR model using OLS\n",
    "def fit_ar_model(returns, lag=1):\n",
    "    \"\"\"\n",
    "    Fit a simple AR model using OLS regression\n",
    "    Returns parameters and fitted values\n",
    "    \"\"\"\n",
    "    y = returns[lag:]\n",
    "    X = np.column_stack([np.ones(len(y)), returns[:-lag]])\n",
    "    \n",
    "    # OLS estimation of parameters\n",
    "    try:\n",
    "        beta = np.linalg.inv(X.T @ X) @ X.T @ y\n",
    "        fitted = X @ beta\n",
    "        return beta, fitted\n",
    "    except:\n",
    "        # If matrix is singular, return simple mean model\n",
    "        mean_return = np.mean(returns)\n",
    "        return np.array([mean_return, 0]), np.full(len(y), mean_return)\n",
    "\n",
    "# Results storage\n",
    "results = {\n",
    "    'cluster': [],\n",
    "    'stock_id': [],\n",
    "    'mse': [],\n",
    "    'qlike': [],\n",
    "    'model_type': []\n",
    "}\n",
    "\n",
    "# Process each cluster\n",
    "for cluster in clustered_data['cluster'].unique():\n",
    "    print(f\"\\nProcessing Cluster {cluster}\")\n",
    "    \n",
    "    # Get stocks in this cluster\n",
    "    cluster_stocks = clustered_data[clustered_data['cluster'] == cluster]['stock_id'].unique()\n",
    "    \n",
    "    # Process each stock in the cluster\n",
    "    for stock_id in cluster_stocks:\n",
    "        print(f\"  Stock {stock_id}\")\n",
    "        \n",
    "        try:\n",
    "            # Load stock data from parquet file\n",
    "            file_path = os.path.join(parquet_dir, f\"stock_{stock_id}.parquet\")\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"    File not found for stock {stock_id}\")\n",
    "                continue\n",
    "                \n",
    "            # Read the parquet file and filter for selected time_ids\n",
    "            df = pd.read_parquet(file_path)\n",
    "            df = df[df['time_id'].isin(selected_time_ids)]\n",
    "            \n",
    "            # Sort and get returns\n",
    "            df = df.sort_values(['time_id', 'seconds_in_bucket'])\n",
    "            returns = df['log_return'].dropna().values\n",
    "            \n",
    "            if len(returns) < 50:  # We need some history for EWMA\n",
    "                print(f\"    Insufficient data for stock {stock_id}\")\n",
    "                continue\n",
    "            \n",
    "            # Handle outliers by winsorizing at 3 standard deviations\n",
    "            std_dev = np.std(returns)\n",
    "            mean_return = np.mean(returns)\n",
    "            upper_bound = mean_return + 3 * std_dev\n",
    "            lower_bound = mean_return - 3 * std_dev\n",
    "            returns_clean = np.clip(returns, lower_bound, upper_bound)\n",
    "            \n",
    "            # Split into train (80%) and test (20%)\n",
    "            split = int(len(returns_clean) * 0.8)\n",
    "            train = returns_clean[:split]\n",
    "            test = returns_clean[split:]\n",
    "            \n",
    "            # 1. Fit AR(1) model for returns using OLS (much more robust than MLE)\n",
    "            ar_params, fitted_returns = fit_ar_model(train, lag=1)\n",
    "            \n",
    "            # 2. Calculate EWMA variance on the training data\n",
    "            train_variance = calculate_ewma_variance(train)\n",
    "            \n",
    "            # Forecast returns for test period using AR(1) model\n",
    "            test_X = np.column_stack([np.ones(len(test)), np.append(train[-1], test[:-1])])\n",
    "            pred_returns = test_X @ ar_params\n",
    "            \n",
    "            # Forecast variance for test period using EWMA\n",
    "            # First we extend the train variance series\n",
    "            full_variance = np.zeros(len(train) + len(test))\n",
    "            full_variance[:len(train)] = train_variance\n",
    "            \n",
    "            # Get the last train variance as starting point\n",
    "            last_train_var = train_variance[-1]\n",
    "            lambda_param = 0.94  # Standard RiskMetrics value\n",
    "            \n",
    "            # Start with the last training variance and forecast forward\n",
    "            pred_variance = np.zeros(len(test))\n",
    "            curr_var = last_train_var\n",
    "            \n",
    "            for i in range(len(test)):\n",
    "                # If we have some test data calculated, use it, otherwise use training data\n",
    "                if i > 0:\n",
    "                    prev_return = test[i-1]\n",
    "                else:\n",
    "                    prev_return = train[-1]\n",
    "                \n",
    "                # EWMA update formula\n",
    "                curr_var = lambda_param * curr_var + (1 - lambda_param) * prev_return**2\n",
    "                pred_variance[i] = curr_var\n",
    "            \n",
    "            # Calculate metrics\n",
    "            mse = mean_squared_error(test, pred_returns)\n",
    "            \n",
    "            # Use squared returns as proxy for actual variance\n",
    "            actual_variance = test**2\n",
    "            qlike = np.mean(calculate_qlike(actual_variance, pred_variance))\n",
    "            \n",
    "            # Store results\n",
    "            results['cluster'].append(cluster)\n",
    "            results['stock_id'].append(stock_id)\n",
    "            results['mse'].append(mse)\n",
    "            results['qlike'].append(qlike)\n",
    "            results['model_type'].append(\"AR(1)-EWMA\")\n",
    "            \n",
    "            print(f\"    Successfully modeled using AR(1)-EWMA\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    Error processing stock {stock_id}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"\\nSuccessfully modeled {len(results_df)} stocks\")\n",
    "\n",
    "# Calculate cluster-level metrics\n",
    "if len(results_df) > 0:\n",
    "    cluster_summary = results_df.groupby('cluster').agg({\n",
    "        'mse': ['mean', 'std', 'count'],\n",
    "        'qlike': ['mean', 'std', 'count']\n",
    "    })\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n--- Cluster Performance Summary ---\")\n",
    "    print(cluster_summary)\n",
    "    \n",
    "    # Find best clusters\n",
    "    if not cluster_summary['mse']['mean'].isna().all():\n",
    "        best_mse_cluster = cluster_summary['mse']['mean'].idxmin()\n",
    "        print(f\"\\nBest cluster by MSE: Cluster {best_mse_cluster}\")\n",
    "    \n",
    "    if not cluster_summary['qlike']['mean'].isna().all():\n",
    "        best_qlike_cluster = cluster_summary['qlike']['mean'].idxmin()\n",
    "        print(f\"Best cluster by QLIKE: Cluster {best_qlike_cluster}\")\n",
    "else:\n",
    "    print(\"\\nNo models successfully computed metrics\")\n",
    "\n",
    "# Save results\n",
    "results_df.to_csv(\"ar_ewma_metrics_by_stock.csv\", index=False)\n",
    "if len(results_df) > 0:\n",
    "    cluster_summary.to_csv(\"ar_ewma_metrics_by_cluster.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec40e0f3",
   "metadata": {},
   "source": [
    "You need to print out results and also refer to papers and articles and then train model on the last few clusters and then have performance metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
